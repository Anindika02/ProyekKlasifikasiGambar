# -*- coding: utf-8 -*-
"""ProyekDicoding.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hYL2zsvQ1Y4g_fIwpa-kkYfBz4bzHhgI

##Proyek Akhir Klasifikasi Gambar##
- Nama: Fairuz Aqila Anindika
- Email: fairuzaqilaanindika02@gmail.com
- ID Dicoding: anindika

#Import Library
"""

import os
import zipfile
from PIL import Image
from collections import defaultdict
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from google.colab import drive
drive.mount('/content/drive')

import zipfile
import os

# Specify the path to the zip file in Google Drive
zip_file_path = '/content/drive/MyDrive/Dataset/satellite.zip'

# Specify the directory to extract to
extract_to = '/content/drive/MyDrive/Dataset'

# Extract the zip file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_to)

print("Extraction completed.")

"""##Melihat jumlah citra dan ukuran resolusi"""

from PIL import Image
from collections import defaultdict

dataset_dir = '/content/drive/MyDrive/Dataset/satellite'

# Dictionary to store resolutions and corresponding image paths
resolution_dict = defaultdict(list)

# Iterate through each subfolder (category)
for category in os.listdir(dataset_dir):
    category_path = os.path.join(dataset_dir, category)

    # Check if it's a directory
    if os.path.isdir(category_path):
        # Iterate through each image in the category folder
        for image_name in os.listdir(category_path):
            image_path = os.path.join(category_path, image_name)

            # Open the image and get its resolution
            with Image.open(image_path) as img:
                resolution = img.size  # (width, height)
                resolution_dict[resolution].append(image_path)

# Check for resolutions with more than one image
print("=== Resolutions Summary ===")
duplicate_count = 0
for resolution, images in resolution_dict.items():
    if len(images) > 1:
        print(f"Resolution {resolution} is shared by {len(images)} images")
        duplicate_count += len(images)

if duplicate_count > 0:
    print(f"Total number of images with duplicated resolutions: {duplicate_count}")
else:
    print("All images have unique resolutions.")

"""##Data Augmentation"""

# Create an instance of ImageDataGenerator for training data with data augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2)  # 20% of the data will be used as validation data

# Create an instance of ImageDataGenerator for validation data (without augmentation)
validation_datagen = ImageDataGenerator(rescale=1./255)

# Generate batches of augmented data for training
train_generator = train_datagen.flow_from_directory(
    dataset_dir,
    target_size=(128, 128),
    batch_size=32,
    class_mode='categorical',
    subset='training',  # Use the training subset
    seed=1000)

# Generate batches of data for validation (without augmentation)
validation_generator = train_datagen.flow_from_directory(
    dataset_dir,
    target_size=(128, 128),
    batch_size=32,
    class_mode='categorical',
    subset='validation',  # Use the validation subset
    seed=1000)

"""##Label"""

# Labels with their class names
class_labels = {class_name: i for i, class_name in enumerate(train_generator.class_indices)}
print(class_labels)

"""#Modelling"""

# Define the model
model = Sequential()
model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(128, 128, 3)))
model.add(MaxPooling2D())
model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))
model.add(MaxPooling2D())
model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
model.add(MaxPooling2D())
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dense(4, activation='softmax')) # 4 classes

model.summary()

# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Define class for early stopping
class EarlyStopping(keras.callbacks.Callback):
    def __init__(self,
                 threshold,
                 patience=2,
                 restore_best_weights='True'):
        super(EarlyStopping, self).__init__()
        self.threshold = threshold

    # Applying early callback
    def on_epoch_end(self, epoch, logs=None):
        val_acc = logs["val_accuracy"]
        if val_acc >= self.threshold:
            self.model.stop_training = True

# Training will stop when validation acc reaches 0.97
mycallback = EarlyStopping(threshold=0.96)
history = model.fit(train_generator,
                    validation_data=validation_generator,
                    epochs=20,
                    verbose=2,
                    callbacks=[mycallback])

# Plotting accuracy
plt.figure(figsize=(12, 5))

# Plot training & validation accuracy values
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')

# Plot training & validation loss values
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(loc='upper right')

# Display the plots
plt.show()

"""#Save Model"""

save_path = 'saved_model/'
tf.saved_model.save(model, save_path)

model.save("h5_model.h5")

keras_model = tf.keras.models.load_model("/content/h5_model.h5")

converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)

tflite_model = converter.convert()

with open('model.tflite', 'wb') as f:
  f.write(tflite_model)

"""#Menyimpan Model dalam Format TensorFlow.js (TFJS)"""

!pip install tensorflowjs

import tensorflowjs as tfjs

# Menyimpan model ke format TFJS

!tensorflowjs_converter --input_format=tf_saved_model 'saved_model/' 'tfjs_model/'

pip freeze requirements.txt